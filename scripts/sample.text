Search | arXiv e-print repository

===============
[Skip to main content](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25#main-container)

[![Image 1: Cornell University](https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg)](https://cornell.edu/)

We gratefully acknowledge support from

 the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors. [Donate](https://info.arxiv.org/about/donate.html)

[![Image 2: arxiv logo](https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)

[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)

Search

[Login](https://arxiv.org/login)

Showing 1–25 of 140,936 results for all: cs.AI
==============================================

[Search v0.5.6 released 2020-02-24](https://github.com/arXiv/arxiv-search/releases)

Search term or terms 

Field 

Search

 Show abstracts   Hide abstracts  

[Advanced Search](https://arxiv.org/search/advanced?terms-0-term=cs.AI&terms-0-field=all&size=25&order=-submitted_date)

*   Show abstracts 
*   Hide abstracts 

results per page . 

Sort results by 

Go

[Previous](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)[Next](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=25)
*   [1](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=0)
*   [2](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=25)
*   [3](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=50)
*   [4](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=75)
*   [5](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=100)
*   …

1.   [arXiv:2509.06956](https://arxiv.org/abs/2509.06956)[[pdf](https://arxiv.org/pdf/2509.06956), [ps](https://arxiv.org/ps/2509.06956), [other](https://arxiv.org/format/2509.06956)]

cs.CV cs.AI cs.LG  
H$_{2}$OT: Hierarchical Hourglass Tokenizer for Efficient Video Pose Transformers

Authors:[Wenhao Li](https://arxiv.org/search/?searchtype=author&query=Li%2C+W), [Mengyuan Liu](https://arxiv.org/search/?searchtype=author&query=Liu%2C+M), [Hong Liu](https://arxiv.org/search/?searchtype=author&query=Liu%2C+H), [Pichao Wang](https://arxiv.org/search/?searchtype=author&query=Wang%2C+P), [Shijian Lu](https://arxiv.org/search/?searchtype=author&query=Lu%2C+S), [Nicu Sebe](https://arxiv.org/search/?searchtype=author&query=Sebe%2C+N)

Abstract:  Transformers have been successfully applied in the field of video-based 3D human pose estimation. However, the high computational costs of these video pose transformers (VPTs) make them impractical on resource-constrained devices. In this paper, we present a hierarchical plug-and-play pruning-and-recovering framework, called Hierarchical Hourglass Tokenizer (H$_{2}$OT), for efficient transformer-b… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Transformers have been successfully applied in the field of video-based 3D human pose estimation. However, the high computational costs of these video pose transformers (VPTs) make them impractical on resource-constrained devices. In this paper, we present a hierarchical plug-and-play pruning-and-recovering framework, called Hierarchical Hourglass Tokenizer (H$_{2}$OT), for efficient transformer-based 3D human pose estimation from videos. H$_{2}$OT begins with progressively pruning pose tokens of redundant frames and ends with recovering full-length sequences, resulting in a few pose tokens in the intermediate transformer blocks and thus improving the model efficiency. It works with two key modules, namely, a Token Pruning Module (TPM) and a Token Recovering Module (TRM). TPM dynamically selects a few representative tokens to eliminate the redundancy of video frames, while TRM restores the detailed spatio-temporal information based on the selected tokens, thereby expanding the network output to the original full-length temporal resolution for fast inference. Our method is general-purpose: it can be easily incorporated into common VPT models on both seq2seq and seq2frame pipelines while effectively accommodating different token pruning and recovery strategies. In addition, our H$_{2}$OT reveals that maintaining the full pose sequence is unnecessary, and a few pose tokens of representative frames can achieve both high efficiency and estimation accuracy. Extensive experiments on multiple benchmark datasets demonstrate both the effectiveness and efficiency of the proposed method. Code and models are available at https://github.com/NationalGAILab/HoT. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

Comments:Accepted by TPAMI 2025, Open Sourced. arXiv admin note: substantial text overlap with arXiv:2311.12028

2.   [arXiv:2406.06464](https://arxiv.org/abs/2406.06464)[[pdf](https://arxiv.org/pdf/2406.06464), [ps](https://arxiv.org/ps/2406.06464), [other](https://arxiv.org/format/2406.06464)]

cs.AI cs.CL  
Transforming Wearable Data into Personal Health Insights using Large Language Model Agents

Authors:[Mike A. Merrill](https://arxiv.org/search/?searchtype=author&query=Merrill%2C+M+A), [Akshay Paruchuri](https://arxiv.org/search/?searchtype=author&query=Paruchuri%2C+A), [Naghmeh Rezaei](https://arxiv.org/search/?searchtype=author&query=Rezaei%2C+N), [Geza Kovacs](https://arxiv.org/search/?searchtype=author&query=Kovacs%2C+G), [Javier Perez](https://arxiv.org/search/?searchtype=author&query=Perez%2C+J), [Yun Liu](https://arxiv.org/search/?searchtype=author&query=Liu%2C+Y), [Erik Schenck](https://arxiv.org/search/?searchtype=author&query=Schenck%2C+E), [Nova Hammerquist](https://arxiv.org/search/?searchtype=author&query=Hammerquist%2C+N), [Jake Sunshine](https://arxiv.org/search/?searchtype=author&query=Sunshine%2C+J), [Shyam Tailor](https://arxiv.org/search/?searchtype=author&query=Tailor%2C+S), [Kumar Ayush](https://arxiv.org/search/?searchtype=author&query=Ayush%2C+K), [Hao-Wei Su](https://arxiv.org/search/?searchtype=author&query=Su%2C+H), [Qian He](https://arxiv.org/search/?searchtype=author&query=He%2C+Q), [Cory Y. McLean](https://arxiv.org/search/?searchtype=author&query=McLean%2C+C+Y), [Mark Malhotra](https://arxiv.org/search/?searchtype=author&query=Malhotra%2C+M), [Shwetak Patel](https://arxiv.org/search/?searchtype=author&query=Patel%2C+S), [Jiening Zhan](https://arxiv.org/search/?searchtype=author&query=Zhan%2C+J), [Tim Althoff](https://arxiv.org/search/?searchtype=author&query=Althoff%2C+T), [Daniel McDuff](https://arxiv.org/search/?searchtype=author&query=McDuff%2C+D), [Xin Liu](https://arxiv.org/search/?searchtype=author&query=Liu%2C+X)

Abstract:  Deriving personalized insights from popular wearable trackers requires complex numerical reasoning that challenges standard LLMs, necessitating tool-based approaches like code generation. Large language model (LLM) agents present a promising yet largely untapped solution for this analysis at scale. We introduce the Personal Health Insights Agent (PHIA), a system leveraging multistep reasoning with… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Deriving personalized insights from popular wearable trackers requires complex numerical reasoning that challenges standard LLMs, necessitating tool-based approaches like code generation. Large language model (LLM) agents present a promising yet largely untapped solution for this analysis at scale. We introduce the Personal Health Insights Agent (PHIA), a system leveraging multistep reasoning with code generation and information retrieval to analyze and interpret behavioral health data. To test its capabilities, we create and share two benchmark datasets with over 4000 health insights questions. A 650-hour human expert evaluation shows that PHIA significantly outperforms a strong code generation baseline, achieving 84% accuracy on objective, numerical questions and, for open-ended ones, earning 83% favorable ratings while being twice as likely to achieve the highest quality rating. This work can advance behavioral health by empowering individuals to understand their data, enabling a new era of accessible, personalized, and data-driven wellness for the wider population. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; v1 submitted 10 June, 2024; originally announced June 2024.

Comments:53 pages, 7 main figures, 2 main tables, accepted to Nature Communications

3.   [arXiv:2509.06953](https://arxiv.org/abs/2509.06953)[[pdf](https://arxiv.org/pdf/2509.06953), [ps](https://arxiv.org/ps/2509.06953), [other](https://arxiv.org/format/2509.06953)]

cs.RO cs.AI cs.CV cs.LG eess.SY  
Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments

Authors:[Jiahui Yang](https://arxiv.org/search/?searchtype=author&query=Yang%2C+J), [Jason Jingzhou Liu](https://arxiv.org/search/?searchtype=author&query=Liu%2C+J+J), [Yulong Li](https://arxiv.org/search/?searchtype=author&query=Li%2C+Y), [Youssef Khaky](https://arxiv.org/search/?searchtype=author&query=Khaky%2C+Y), [Kenneth Shaw](https://arxiv.org/search/?searchtype=author&query=Shaw%2C+K), [Deepak Pathak](https://arxiv.org/search/?searchtype=author&query=Pathak%2C+D)

Abstract:  Generating collision-free motion in dynamic, partially observable environments is a fundamental challenge for robotic manipulators. Classical motion planners can compute globally optimal trajectories but require full environment knowledge and are typically too slow for dynamic scenes. Neural motion policies offer a promising alternative by operating in closed-loop directly on raw sensory inputs bu… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Generating collision-free motion in dynamic, partially observable environments is a fundamental challenge for robotic manipulators. Classical motion planners can compute globally optimal trajectories but require full environment knowledge and are typically too slow for dynamic scenes. Neural motion policies offer a promising alternative by operating in closed-loop directly on raw sensory inputs but often struggle to generalize in complex or dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural motion policy designed for reactive motion generation in diverse dynamic environments, operating directly on point cloud sensory input. At its core is IMPACT, a transformer-based neural motion policy pretrained on 10 million generated expert trajectories across diverse simulation scenarios. We further improve IMPACT's static obstacle avoidance through iterative student-teacher finetuning. We additionally enhance the policy's dynamic obstacle avoidance at inference time using DCP-RMP, a locally reactive goal-proposal module. We evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving obstacles, and goal obstructions. DRP achieves strong generalization, outperforming prior classical and neural methods in success rate across both simulated and real-world settings. Video results and code available at https://deep-reactive-policy.com [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

Comments:Website at \url{deep-reactive-policy.com}

4.   [arXiv:2509.06945](https://arxiv.org/abs/2509.06945)[[pdf](https://arxiv.org/pdf/2509.06945), [ps](https://arxiv.org/ps/2509.06945), [other](https://arxiv.org/format/2509.06945)]

cs.CV cs.AI cs.CL cs.LG  
Interleaving Reasoning for Better Text-to-Image Generation

Authors:[Wenxuan Huang](https://arxiv.org/search/?searchtype=author&query=Huang%2C+W), [Shuang Chen](https://arxiv.org/search/?searchtype=author&query=Chen%2C+S), [Zheyong Xie](https://arxiv.org/search/?searchtype=author&query=Xie%2C+Z), [Shaosheng Cao](https://arxiv.org/search/?searchtype=author&query=Cao%2C+S), [Shixiang Tang](https://arxiv.org/search/?searchtype=author&query=Tang%2C+S), [Yufan Shen](https://arxiv.org/search/?searchtype=author&query=Shen%2C+Y), [Qingyu Yin](https://arxiv.org/search/?searchtype=author&query=Yin%2C+Q), [Wenbo Hu](https://arxiv.org/search/?searchtype=author&query=Hu%2C+W), [Xiaoman Wang](https://arxiv.org/search/?searchtype=author&query=Wang%2C+X), [Yuntian Tang](https://arxiv.org/search/?searchtype=author&query=Tang%2C+Y), [Junbo Qiao](https://arxiv.org/search/?searchtype=author&query=Qiao%2C+J), [Yue Guo](https://arxiv.org/search/?searchtype=author&query=Guo%2C+Y), [Yao Hu](https://arxiv.org/search/?searchtype=author&query=Hu%2C+Y), [Zhenfei Yin](https://arxiv.org/search/?searchtype=author&query=Yin%2C+Z), [Philip Torr](https://arxiv.org/search/?searchtype=author&query=Torr%2C+P), [Yu Cheng](https://arxiv.org/search/?searchtype=author&query=Cheng%2C+Y), [Wanli Ouyang](https://arxiv.org/search/?searchtype=author&query=Ouyang%2C+W), [Shaohui Lin](https://arxiv.org/search/?searchtype=author&query=Lin%2C+S)

Abstract:  Unified multimodal understanding and generation models recently have achieve significant improvement in image generation capability, yet a large gap remains in instruction following and detail preservation compared to systems that tightly couple comprehension with generation such as GPT-4o. Motivated by recent advances in interleaving reasoning, we explore whether such reasoning can further improv… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Unified multimodal understanding and generation models recently have achieve significant improvement in image generation capability, yet a large gap remains in instruction following and detail preservation compared to systems that tightly couple comprehension with generation such as GPT-4o. Motivated by recent advances in interleaving reasoning, we explore whether such reasoning can further improve Text-to-Image (T2I) generation. We introduce Interleaving Reasoning Generation (IRG), a framework that alternates between text-based thinking and image synthesis: the model first produces a text-based thinking to guide an initial image, then reflects on the result to refine fine-grained details, visual quality, and aesthetics while preserving semantics. To train IRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL), which targets two sub-goals: (1) strengthening the initial think-and-generate stage to establish core content and base quality, and (2) enabling high-quality textual reflection and faithful implementation of those refinements in a subsequent image. We curate IRGL-300K, a dataset organized into six decomposed learning modes that jointly cover learning text-based thinking, and full thinking-image trajectories. Starting from a unified foundation model that natively emits interleaved text-image outputs, our two-stage training first builds robust thinking and reflection, then efficiently tunes the IRG pipeline in the full thinking-image trajectory data. Extensive experiments show SoTA performance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF, GenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality and fine-grained fidelity. The code, model weights and datasets will be released in: https://github.com/Osilly/Interleaving-Reasoning-Generation . [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

5.   [arXiv:2509.06942](https://arxiv.org/abs/2509.06942)[[pdf](https://arxiv.org/pdf/2509.06942), [ps](https://arxiv.org/ps/2509.06942), [other](https://arxiv.org/format/2509.06942)]

cs.AI cs.LG  
Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference

Authors:[Xiangwei Shen](https://arxiv.org/search/?searchtype=author&query=Shen%2C+X), [Zhimin Li](https://arxiv.org/search/?searchtype=author&query=Li%2C+Z), [Zhantao Yang](https://arxiv.org/search/?searchtype=author&query=Yang%2C+Z), [Shiyi Zhang](https://arxiv.org/search/?searchtype=author&query=Zhang%2C+S), [Yingfang Zhang](https://arxiv.org/search/?searchtype=author&query=Zhang%2C+Y), [Donghao Li](https://arxiv.org/search/?searchtype=author&query=Li%2C+D), [Chunyu Wang](https://arxiv.org/search/?searchtype=author&query=Wang%2C+C), [Qinglin Lu](https://arxiv.org/search/?searchtype=author&query=Lu%2C+Q), [Yansong Tang](https://arxiv.org/search/?searchtype=author&query=Tang%2C+Y)

Abstract:  Recent studies have demonstrated the effectiveness of directly aligning diffusion models with human preferences using differentiable reward. However, they exhibit two primary challenges: (1) they rely on multistep denoising with gradient computation for reward scoring, which is computationally expensive, thus restricting optimization to only a few diffusion steps; (2) they often need continuous of… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Recent studies have demonstrated the effectiveness of directly aligning diffusion models with human preferences using differentiable reward. However, they exhibit two primary challenges: (1) they rely on multistep denoising with gradient computation for reward scoring, which is computationally expensive, thus restricting optimization to only a few diffusion steps; (2) they often need continuous offline adaptation of reward models in order to achieve desired aesthetic quality, such as photorealism or precise lighting effects. To address the limitation of multistep denoising, we propose Direct-Align, a method that predefines a noise prior to effectively recover original images from any time steps via interpolation, leveraging the equation that diffusion states are interpolations between noise and target images, which effectively avoids over-optimization in late timesteps. Furthermore, we introduce Semantic Relative Preference Optimization (SRPO), in which rewards are formulated as text-conditioned signals. This approach enables online adjustment of rewards in response to positive and negative prompt augmentation, thereby reducing the reliance on offline reward fine-tuning. By fine-tuning the FLUX.1.dev model with optimized denoising and online reward adjustment, we improve its human-evaluated realism and aesthetic quality by over 3x. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

Comments:15 pages

6.   [arXiv:2509.06938](https://arxiv.org/abs/2509.06938)[[pdf](https://arxiv.org/pdf/2509.06938), [ps](https://arxiv.org/ps/2509.06938), [other](https://arxiv.org/format/2509.06938)]

cs.LG cs.AI  
From Noise to Narrative: Tracing the Origins of Hallucinations in Transformers

Authors:[Praneet Suresh](https://arxiv.org/search/?searchtype=author&query=Suresh%2C+P), [Jack Stanley](https://arxiv.org/search/?searchtype=author&query=Stanley%2C+J), [Sonia Joseph](https://arxiv.org/search/?searchtype=author&query=Joseph%2C+S), [Luca Scimeca](https://arxiv.org/search/?searchtype=author&query=Scimeca%2C+L), [Danilo Bzdok](https://arxiv.org/search/?searchtype=author&query=Bzdok%2C+D)

Abstract:  As generative AI systems become competent and democratized in science, business, and government, deeper insight into their failure modes now poses an acute need. The occasional volatility in their behavior, such as the propensity of transformer models to hallucinate, impedes trust and adoption of emerging AI solutions in high-stakes areas. In the present work, we establish how and when hallucinati… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) As generative AI systems become competent and democratized in science, business, and government, deeper insight into their failure modes now poses an acute need. The occasional volatility in their behavior, such as the propensity of transformer models to hallucinate, impedes trust and adoption of emerging AI solutions in high-stakes areas. In the present work, we establish how and when hallucinations arise in pre-trained transformer models through concept representations captured by sparse autoencoders, under scenarios with experimentally controlled uncertainty in the input space. Our systematic experiments reveal that the number of semantic concepts used by the transformer model grows as the input information becomes increasingly unstructured. In the face of growing uncertainty in the input space, the transformer model becomes prone to activate coherent yet input-insensitive semantic features, leading to hallucinated output. At its extreme, for pure-noise inputs, we identify a wide variety of robustly triggered and meaningful concepts in the intermediate activations of pre-trained transformer models, whose functional integrity we confirm through targeted steering. We also show that hallucinations in the output of a transformer model can be reliably predicted from the concept patterns embedded in transformer layer activations. This collection of insights on transformer internal processing mechanics has immediate consequences for aligning AI models with human values, AI safety, opening the attack surface for potential adversarial attacks, and providing a basis for automatic quantification of a model's hallucination risk. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

7.   [arXiv:2509.06921](https://arxiv.org/abs/2509.06921)[[pdf](https://arxiv.org/pdf/2509.06921), [ps](https://arxiv.org/ps/2509.06921), [other](https://arxiv.org/format/2509.06921)]

cs.CR cs.AI  
Neuro-Symbolic AI for Cybersecurity: State of the Art, Challenges, and Opportunities

Authors:[Safayat Bin Hakim](https://arxiv.org/search/?searchtype=author&query=Hakim%2C+S+B), [Muhammad Adil](https://arxiv.org/search/?searchtype=author&query=Adil%2C+M), [Alvaro Velasquez](https://arxiv.org/search/?searchtype=author&query=Velasquez%2C+A), [Shouhuai Xu](https://arxiv.org/search/?searchtype=author&query=Xu%2C+S), [Houbing Herbert Song](https://arxiv.org/search/?searchtype=author&query=Song%2C+H+H)

Abstract:  Traditional Artificial Intelligence (AI) approaches in cybersecurity exhibit fundamental limitations: inadequate conceptual grounding leading to non-robustness against novel attacks; limited instructibility impeding analyst-guided adaptation; and misalignment with cybersecurity objectives. Neuro-Symbolic (NeSy) AI has emerged with the potential to revolutionize cybersecurity AI. However, there is… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Traditional Artificial Intelligence (AI) approaches in cybersecurity exhibit fundamental limitations: inadequate conceptual grounding leading to non-robustness against novel attacks; limited instructibility impeding analyst-guided adaptation; and misalignment with cybersecurity objectives. Neuro-Symbolic (NeSy) AI has emerged with the potential to revolutionize cybersecurity AI. However, there is no systematic understanding of this emerging approach. These hybrid systems address critical cybersecurity challenges by combining neural pattern recognition with symbolic reasoning, enabling enhanced threat understanding while introducing concerning autonomous offensive capabilities that reshape threat landscapes. In this survey, we systematically characterize this field by analyzing 127 publications spanning 2019-July 2025. We introduce a Grounding-Instructibility-Alignment (G-I-A) framework to evaluate these systems, focusing on both cyber defense and cyber offense across network security, malware analysis, and cyber operations. Our analysis shows advantages of multi-agent NeSy architectures and identifies critical implementation challenges including standardization gaps, computational complexity, and human-AI collaboration requirements that constrain deployment. We show that causal reasoning integration is the most transformative advancement, enabling proactive defense beyond correlation-based approaches. Our findings highlight dual-use implications where autonomous systems demonstrate substantial capabilities in zero-day exploitation while achieving significant cost reductions, altering threat dynamics. We provide insights and future research directions, emphasizing the urgent need for community-driven standardization frameworks and responsible development practices that ensure advancement serves defensive cybersecurity objectives while maintaining societal alignment. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

8.   [arXiv:2509.06920](https://arxiv.org/abs/2509.06920)[[pdf](https://arxiv.org/pdf/2509.06920), [ps](https://arxiv.org/ps/2509.06920), [other](https://arxiv.org/format/2509.06920)]

cs.CR cs.AI cs.CL cs.CY  
An Ethically Grounded LLM-Based Approach to Insider Threat Synthesis and Detection

Authors:[Haywood Gelman](https://arxiv.org/search/?searchtype=author&query=Gelman%2C+H), [John D. Hastings](https://arxiv.org/search/?searchtype=author&query=Hastings%2C+J+D), [David Kenley](https://arxiv.org/search/?searchtype=author&query=Kenley%2C+D)

Abstract:  Insider threats are a growing organizational problem due to the complexity of identifying their technical and behavioral elements. A large research body is dedicated to the study of insider threats from technological, psychological, and educational perspectives. However, research in this domain has been generally dependent on datasets that are static and limited access which restricts the developm… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Insider threats are a growing organizational problem due to the complexity of identifying their technical and behavioral elements. A large research body is dedicated to the study of insider threats from technological, psychological, and educational perspectives. However, research in this domain has been generally dependent on datasets that are static and limited access which restricts the development of adaptive detection models. This study introduces a novel, ethically grounded approach that uses the large language model (LLM) Claude Sonnet 3.7 to dynamically synthesize syslog messages, some of which contain indicators of insider threat scenarios. The messages reflect real-world data distributions by being highly imbalanced (1% insider threats). The syslogs were analyzed for insider threats by both Claude Sonnet 3.7 and GPT-4o, with their performance evaluated through statistical metrics including precision, recall, MCC, and ROC AUC. Sonnet 3.7 consistently outperformed GPT-4o across nearly all metrics, particularly in reducing false alarms and improving detection accuracy. The results show strong promise for the use of LLMs in synthetic dataset generation and insider threat detection. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

Comments:6 pages, 5 figures, 5 tables

ACM Class: C.2.0; I.2.7; K.4.1; H.3.3

9.   [arXiv:2509.06918](https://arxiv.org/abs/2509.06918)[[pdf](https://arxiv.org/pdf/2509.06918), [ps](https://arxiv.org/ps/2509.06918), [other](https://arxiv.org/format/2509.06918)]

cs.LG cs.AI  
Tackling the Noisy Elephant in the Room: Label Noise-robust Out-of-Distribution Detection via Loss Correction and Low-rank Decomposition

Authors:[Tarhib Al Azad](https://arxiv.org/search/?searchtype=author&query=Azad%2C+T+A), [Shahana Ibrahim](https://arxiv.org/search/?searchtype=author&query=Ibrahim%2C+S)

Abstract:  Robust out-of-distribution (OOD) detection is an indispensable component of modern artificial intelligence (AI) systems, especially in safety-critical applications where models must identify inputs from unfamiliar classes not seen during training. While OOD detection has been extensively studied in the machine learning literature--with both post hoc and training-based approaches--its effectiveness… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Robust out-of-distribution (OOD) detection is an indispensable component of modern artificial intelligence (AI) systems, especially in safety-critical applications where models must identify inputs from unfamiliar classes not seen during training. While OOD detection has been extensively studied in the machine learning literature--with both post hoc and training-based approaches--its effectiveness under noisy training labels remains underexplored. Recent studies suggest that label noise can significantly degrade OOD performance, yet principled solutions to this issue are lacking. In this work, we demonstrate that directly combining existing label noise-robust methods with OOD detection strategies is insufficient to address this critical challenge. To overcome this, we propose a robust OOD detection framework that integrates loss correction techniques from the noisy label learning literature with low-rank and sparse decomposition methods from signal processing. Extensive experiments on both synthetic and real-world datasets demonstrate that our method significantly outperforms the state-of-the-art OOD detection techniques, particularly under severe noisy label settings. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

10.   [arXiv:2509.06917](https://arxiv.org/abs/2509.06917)[[pdf](https://arxiv.org/pdf/2509.06917), [ps](https://arxiv.org/ps/2509.06917), [other](https://arxiv.org/format/2509.06917)]

cs.AI cs.CL cs.LG  
Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents

Authors:[Jiacheng Miao](https://arxiv.org/search/?searchtype=author&query=Miao%2C+J), [Joe R. Davis](https://arxiv.org/search/?searchtype=author&query=Davis%2C+J+R), [Jonathan K. Pritchard](https://arxiv.org/search/?searchtype=author&query=Pritchard%2C+J+K), [James Zou](https://arxiv.org/search/?searchtype=author&query=Zou%2C+J)

Abstract:  We introduce Paper2Agent, an automated framework that converts research papers into AI agents. Paper2Agent transforms research output from passive artifacts into active systems that can accelerate downstream use, adoption, and discovery. Conventional research papers require readers to invest substantial effort to understand and adapt a paper's code, data, and methods to their own work, creating ba… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) We introduce Paper2Agent, an automated framework that converts research papers into AI agents. Paper2Agent transforms research output from passive artifacts into active systems that can accelerate downstream use, adoption, and discovery. Conventional research papers require readers to invest substantial effort to understand and adapt a paper's code, data, and methods to their own work, creating barriers to dissemination and reuse. Paper2Agent addresses this challenge by automatically converting a paper into an AI agent that acts as a knowledgeable research assistant. It systematically analyzes the paper and the associated codebase using multiple agents to construct a Model Context Protocol (MCP) server, then iteratively generates and runs tests to refine and robustify the resulting MCP. These paper MCPs can then be flexibly connected to a chat agent (e.g. Claude Code) to carry out complex scientific queries through natural language while invoking tools and workflows from the original paper. We demonstrate Paper2Agent's effectiveness in creating reliable and capable paper agents through in-depth case studies. Paper2Agent created an agent that leverages AlphaGenome to interpret genomic variants and agents based on ScanPy and TISSUE to carry out single-cell and spatial transcriptomics analyses. We validate that these paper agents can reproduce the original paper's results and can correctly carry out novel user queries. By turning static papers into dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for knowledge dissemination and a foundation for the collaborative ecosystem of AI co-scientists. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

11.   [arXiv:2504.18026](https://arxiv.org/abs/2504.18026)[[pdf](https://arxiv.org/pdf/2504.18026), [ps](https://arxiv.org/ps/2504.18026), [other](https://arxiv.org/format/2504.18026)]

cs.LG cs.AI  
Addressing Concept Mislabeling in Concept Bottleneck Models Through Preference Optimization

Authors:[Emiliano Penaloza](https://arxiv.org/search/?searchtype=author&query=Penaloza%2C+E), [Tianyue H. Zhang](https://arxiv.org/search/?searchtype=author&query=Zhang%2C+T+H), [Laurent Charlin](https://arxiv.org/search/?searchtype=author&query=Charlin%2C+L), [Mateo Espinosa Zarlenga](https://arxiv.org/search/?searchtype=author&query=Zarlenga%2C+M+E)

Abstract:  Concept Bottleneck Models (CBMs) propose to enhance the trustworthiness of AI systems by constraining their decisions on a set of human-understandable concepts. However, CBMs typically assume that datasets contain accurate concept labels-an assumption often violated in practice, which we show can significantly degrade performance (by 25% in some cases). To address this, we introduce the Concept Pr… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Concept Bottleneck Models (CBMs) propose to enhance the trustworthiness of AI systems by constraining their decisions on a set of human-understandable concepts. However, CBMs typically assume that datasets contain accurate concept labels-an assumption often violated in practice, which we show can significantly degrade performance (by 25% in some cases). To address this, we introduce the Concept Preference Optimization (CPO) objective, a new loss function based on Direct Preference Optimization, which effectively mitigates the negative impact of concept mislabeling on CBM performance. We provide an analysis of key properties of the CPO objective, showing it directly optimizes for the concept's posterior distribution, and contrast it against Binary Cross Entropy (BCE), demonstrating that CPO is inherently less sensitive to concept noise. We empirically confirm our analysis by finding that CPO consistently outperforms BCE on three real-world datasets, both with and without added label noise. We make our code available on Github. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; v1 submitted 24 April, 2025; originally announced April 2025.

12.   [arXiv:2509.06885](https://arxiv.org/abs/2509.06885)[[pdf](https://arxiv.org/pdf/2509.06885), [ps](https://arxiv.org/ps/2509.06885), [other](https://arxiv.org/format/2509.06885)]

cs.CV cs.AI  
Barlow-Swin: Toward a novel siamese-based segmentation architecture using Swin-Transformers

Authors:[Morteza Kiani Haftlang](https://arxiv.org/search/?searchtype=author&query=Haftlang%2C+M+K), [Mohammadhossein Malmir](https://arxiv.org/search/?searchtype=author&query=Malmir%2C+M), [Foroutan Parand](https://arxiv.org/search/?searchtype=author&query=Parand%2C+F), [Umberto Michelucci](https://arxiv.org/search/?searchtype=author&query=Michelucci%2C+U), [Safouane El Ghazouali](https://arxiv.org/search/?searchtype=author&query=Ghazouali%2C+S+E)

Abstract:  Medical image segmentation is a critical task in clinical workflows, particularly for the detection and delineation of pathological regions. While convolutional architectures like U-Net have become standard for such tasks, their limited receptive field restricts global context modeling. Recent efforts integrating transformers have addressed this, but often result in deep, computationally expensive… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Medical image segmentation is a critical task in clinical workflows, particularly for the detection and delineation of pathological regions. While convolutional architectures like U-Net have become standard for such tasks, their limited receptive field restricts global context modeling. Recent efforts integrating transformers have addressed this, but often result in deep, computationally expensive models unsuitable for real-time use. In this work, we present a novel end-to-end lightweight architecture designed specifically for real-time binary medical image segmentation. Our model combines a Swin Transformer-like encoder with a U-Net-like decoder, connected via skip pathways to preserve spatial detail while capturing contextual information. Unlike existing designs such as Swin Transformer or U-Net, our architecture is significantly shallower and competitively efficient. To improve the encoder's ability to learn meaningful features without relying on large amounts of labeled data, we first train it using Barlow Twins, a self-supervised learning method that helps the model focus on important patterns by reducing unnecessary repetition in the learned features. After this pretraining, we fine-tune the entire model for our specific task. Experiments on benchmark binary segmentation tasks demonstrate that our model achieves competitive accuracy with substantially reduced parameter count and faster inference, positioning it as a practical alternative for deployment in real-time and resource-limited clinical environments. The code for our method is available at Github repository: https://github.com/mkianih/Barlow-Swin. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

13.   [arXiv:2509.05263](https://arxiv.org/abs/2509.05263)[[pdf](https://arxiv.org/pdf/2509.05263), [ps](https://arxiv.org/ps/2509.05263), [other](https://arxiv.org/format/2509.05263)]

cs.AI cs.CV cs.LG  
LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation

Authors:[Yinglin Duan](https://arxiv.org/search/?searchtype=author&query=Duan%2C+Y), [Zhengxia Zou](https://arxiv.org/search/?searchtype=author&query=Zou%2C+Z), [Tongwei Gu](https://arxiv.org/search/?searchtype=author&query=Gu%2C+T), [Wei Jia](https://arxiv.org/search/?searchtype=author&query=Jia%2C+W), [Zhan Zhao](https://arxiv.org/search/?searchtype=author&query=Zhao%2C+Z), [Luyi Xu](https://arxiv.org/search/?searchtype=author&query=Xu%2C+L), [Xinzhu Liu](https://arxiv.org/search/?searchtype=author&query=Liu%2C+X), [Yenan Lin](https://arxiv.org/search/?searchtype=author&query=Lin%2C+Y), [Hao Jiang](https://arxiv.org/search/?searchtype=author&query=Jiang%2C+H), [Kang Chen](https://arxiv.org/search/?searchtype=author&query=Chen%2C+K), [Shuang Qiu](https://arxiv.org/search/?searchtype=author&query=Qiu%2C+S)

Abstract:  Recent research has been increasingly focusing on developing 3D world models that simulate complex real-world scenarios. World models have found broad applications across various domains, including embodied AI, autonomous driving, entertainment, etc. A more realistic simulation with accurate physics will effectively narrow the sim-to-real gap and allow us to gather rich information about the real… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Recent research has been increasingly focusing on developing 3D world models that simulate complex real-world scenarios. World models have found broad applications across various domains, including embodied AI, autonomous driving, entertainment, etc. A more realistic simulation with accurate physics will effectively narrow the sim-to-real gap and allow us to gather rich information about the real world conveniently. While traditional manual modeling has enabled the creation of virtual 3D scenes, modern approaches have leveraged advanced machine learning algorithms for 3D world generation, with most recent advances focusing on generative methods that can create virtual worlds based on user instructions. This work explores such a research direction by proposing LatticeWorld, a simple yet effective 3D world generation framework that streamlines the industrial production pipeline of 3D environments. LatticeWorld leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed framework accepts textual descriptions and visual instructions as multimodal inputs and creates large-scale 3D interactive worlds with dynamic agents, featuring competitive multi-agent interaction, high-fidelity physics simulation, and real-time rendering. We conduct comprehensive experiments to evaluate LatticeWorld, showing that it achieves superior accuracy in scene layout generation and visual fidelity. Moreover, LatticeWorld achieves over a $90\times$ increase in industrial production efficiency while maintaining high creative quality compared with traditional manual production methods. Our demo video is available at https://youtu.be/8VWZXpERR18 [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; v1 submitted 5 September, 2025; originally announced September 2025.

14.   [arXiv:2509.06883](https://arxiv.org/abs/2509.06883)[[pdf](https://arxiv.org/pdf/2509.06883), [ps](https://arxiv.org/ps/2509.06883), [other](https://arxiv.org/format/2509.06883)]

cs.CL cs.AI cs.IR  
UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction

Authors:[Joe Wilder](https://arxiv.org/search/?searchtype=author&query=Wilder%2C+J), [Nikhil Kadapala](https://arxiv.org/search/?searchtype=author&query=Kadapala%2C+N), [Benji Xu](https://arxiv.org/search/?searchtype=author&query=Xu%2C+B), [Mohammed Alsaadi](https://arxiv.org/search/?searchtype=author&query=Alsaadi%2C+M), [Aiden Parsons](https://arxiv.org/search/?searchtype=author&query=Parsons%2C+A), [Mitchell Rogers](https://arxiv.org/search/?searchtype=author&query=Rogers%2C+M), [Palash Agarwal](https://arxiv.org/search/?searchtype=author&query=Agarwal%2C+P), [Adam Hassick](https://arxiv.org/search/?searchtype=author&query=Hassick%2C+A), [Laura Dietz](https://arxiv.org/search/?searchtype=author&query=Dietz%2C+L)

Abstract:  We participate in CheckThat! Task 2 English and explore various methods of prompting and in-context learning, including few-shot prompting and fine-tuning with different LLM families, with the goal of extracting check-worthy claims from social media passages. Our best METEOR score is achieved by fine-tuning a FLAN-T5 model. However, we observe that higher-quality claims can sometimes be extracted… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) We participate in CheckThat! Task 2 English and explore various methods of prompting and in-context learning, including few-shot prompting and fine-tuning with different LLM families, with the goal of extracting check-worthy claims from social media passages. Our best METEOR score is achieved by fine-tuning a FLAN-T5 model. However, we observe that higher-quality claims can sometimes be extracted using other methods, even when their METEOR scores are lower. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

Comments:16 pages,3 tables, CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain

15.   [arXiv:2509.06875](https://arxiv.org/abs/2509.06875)[[pdf](https://arxiv.org/pdf/2509.06875), [ps](https://arxiv.org/ps/2509.06875), [other](https://arxiv.org/format/2509.06875)]

cs.LG cs.AI  
AxelSMOTE: An Agent-Based Oversampling Algorithm for Imbalanced Classification

Authors:[Sukumar Kishanthan](https://arxiv.org/search/?searchtype=author&query=Kishanthan%2C+S), [Asela Hevapathige](https://arxiv.org/search/?searchtype=author&query=Hevapathige%2C+A)

Abstract:  Class imbalance in machine learning poses a significant challenge, as skewed datasets often hinder performance on minority classes. Traditional oversampling techniques, which are commonly used to alleviate class imbalance, have several drawbacks: they treat features independently, lack similarity-based controls, limit sample diversity, and fail to manage synthetic variety effectively. To overcome… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Class imbalance in machine learning poses a significant challenge, as skewed datasets often hinder performance on minority classes. Traditional oversampling techniques, which are commonly used to alleviate class imbalance, have several drawbacks: they treat features independently, lack similarity-based controls, limit sample diversity, and fail to manage synthetic variety effectively. To overcome these issues, we introduce AxelSMOTE, an innovative agent-based approach that views data instances as autonomous agents engaging in complex interactions. Based on Axelrod's cultural dissemination model, AxelSMOTE implements four key innovations: (1) trait-based feature grouping to preserve correlations; (2) a similarity-based probabilistic exchange mechanism for meaningful interactions; (3) Beta distribution blending for realistic interpolation; and (4) controlled diversity injection to avoid overfitting. Experiments on eight imbalanced datasets demonstrate that AxelSMOTE outperforms state-of-the-art sampling methods while maintaining computational efficiency. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

16.   [arXiv:2504.13146](https://arxiv.org/abs/2504.13146)[[pdf](https://arxiv.org/pdf/2504.13146), [ps](https://arxiv.org/ps/2504.13146), [other](https://arxiv.org/format/2504.13146)]

cs.AI cs.CL  
Antidistillation Sampling

Authors:[Yash Savani](https://arxiv.org/search/?searchtype=author&query=Savani%2C+Y), [Asher Trockman](https://arxiv.org/search/?searchtype=author&query=Trockman%2C+A), [Zhili Feng](https://arxiv.org/search/?searchtype=author&query=Feng%2C+Z), [Yixuan Even Xu](https://arxiv.org/search/?searchtype=author&query=Xu%2C+Y+E), [Avi Schwarzschild](https://arxiv.org/search/?searchtype=author&query=Schwarzschild%2C+A), [Alexander Robey](https://arxiv.org/search/?searchtype=author&query=Robey%2C+A), [Marc Finzi](https://arxiv.org/search/?searchtype=author&query=Finzi%2C+M), [J. Zico Kolter](https://arxiv.org/search/?searchtype=author&query=Kolter%2C+J+Z)

Abstract:  Frontier models that generate extended reasoning traces inadvertently produce rich token sequences that can facilitate model distillation. Recognizing this vulnerability, model owners may seek sampling strategies that limit the effectiveness of distillation without compromising model performance. Antidistillation sampling provides exactly this capability. By strategically modifying a model's next-… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Frontier models that generate extended reasoning traces inadvertently produce rich token sequences that can facilitate model distillation. Recognizing this vulnerability, model owners may seek sampling strategies that limit the effectiveness of distillation without compromising model performance. Antidistillation sampling provides exactly this capability. By strategically modifying a model's next-token probability distribution, antidistillation sampling poisons reasoning traces, rendering them significantly less effective for distillation while preserving the model's practical utility. For further details, see https://antidistillation.com. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; v1 submitted 17 April, 2025; originally announced April 2025.

17.   [arXiv:2505.20521](https://arxiv.org/abs/2505.20521)[[pdf](https://arxiv.org/pdf/2505.20521), [ps](https://arxiv.org/ps/2505.20521), [other](https://arxiv.org/format/2505.20521)]

cs.AI cs.CL  
Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting

Authors:[Ana Rita Ortigoso](https://arxiv.org/search/?searchtype=author&query=Ortigoso%2C+A+R), [Gabriel Vieira](https://arxiv.org/search/?searchtype=author&query=Vieira%2C+G), [Daniel Fuentes](https://arxiv.org/search/?searchtype=author&query=Fuentes%2C+D), [Luis Frazão](https://arxiv.org/search/?searchtype=author&query=Fraz%C3%A3o%2C+L), [Nuno Costa](https://arxiv.org/search/?searchtype=author&query=Costa%2C+N), [António Pereira](https://arxiv.org/search/?searchtype=author&query=Pereira%2C+A)

Abstract:  This paper presents Project Riley, a novel multimodal and multi-model conversational AI architecture oriented towards the simulation of reasoning influenced by emotional states. Drawing inspiration from Pixar's Inside Out, the system comprises five distinct emotional agents - Joy, Sadness, Fear, Anger, and Disgust - that engage in structured multi-round dialogues to generate, criticise, and iterat… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) This paper presents Project Riley, a novel multimodal and multi-model conversational AI architecture oriented towards the simulation of reasoning influenced by emotional states. Drawing inspiration from Pixar's Inside Out, the system comprises five distinct emotional agents - Joy, Sadness, Fear, Anger, and Disgust - that engage in structured multi-round dialogues to generate, criticise, and iteratively refine responses. A final reasoning mechanism synthesises the contributions of these agents into a coherent output that either reflects the dominant emotion or integrates multiple perspectives. The architecture incorporates both textual and visual large language models (LLMs), alongside advanced reasoning and self-refinement processes. A functional prototype was deployed locally in an offline environment, optimised for emotional expressiveness and computational efficiency. From this initial prototype, another one emerged, called Armando, which was developed for use in emergency contexts, delivering emotionally calibrated and factually accurate information through the integration of Retrieval-Augmented Generation (RAG) and cumulative context tracking. The Project Riley prototype was evaluated through user testing, in which participants interacted with the chatbot and completed a structured questionnaire assessing three dimensions: Emotional Appropriateness, Clarity and Utility, and Naturalness and Human-likeness. The results indicate strong performance in structured scenarios, particularly with respect to emotional alignment and communicative clarity. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; v1 submitted 26 May, 2025; originally announced May 2025.

Comments:28 pages, 5 figures. Submitted for review to Information Fusion

ACM Class: I.2.7; I.2.1; H.5.2

18.   [arXiv:2502.18658](https://arxiv.org/abs/2502.18658)[[pdf](https://arxiv.org/pdf/2502.18658), [ps](https://arxiv.org/ps/2502.18658), [other](https://arxiv.org/format/2502.18658)]

cs.HC cs.AI cs.SE doi[10.1145/3706598.3713357](https://doi.org/10.1145/3706598.3713357)   
Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support

Authors:[Kevin Pu](https://arxiv.org/search/?searchtype=author&query=Pu%2C+K), [Daniel Lazaro](https://arxiv.org/search/?searchtype=author&query=Lazaro%2C+D), [Ian Arawjo](https://arxiv.org/search/?searchtype=author&query=Arawjo%2C+I), [Haijun Xia](https://arxiv.org/search/?searchtype=author&query=Xia%2C+H), [Ziang Xiao](https://arxiv.org/search/?searchtype=author&query=Xiao%2C+Z), [Tovi Grossman](https://arxiv.org/search/?searchtype=author&query=Grossman%2C+T), [Yan Chen](https://arxiv.org/search/?searchtype=author&query=Chen%2C+Y)

Abstract:  AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-off… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-offs between increasingly salient AI support: prompt-only, proactive agent, and proactive agent with presence and context (Codellaborator). In a within-subject study (N=18), we find that proactive agents increase efficiency compared to prompt-only paradigm, but also incur workflow disruptions. However, presence indicators and interaction context support alleviated disruptions and improved users' awareness of AI processes. We underscore trade-offs of Codellaborator on user control, ownership, and code understanding, emphasizing the need to adapt proactivity to programming processes. Our research contributes to the design exploration and evaluation of proactive AI systems, presenting design implications on AI-integrated programming workflow. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; v1 submitted 25 February, 2025; originally announced February 2025.

19.   [arXiv:2509.06863](https://arxiv.org/abs/2509.06863)[[pdf](https://arxiv.org/pdf/2509.06863), [ps](https://arxiv.org/ps/2509.06863), [other](https://arxiv.org/format/2509.06863)]

cs.LG cs.AI  
floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL

Authors:[Bhavya Agrawalla](https://arxiv.org/search/?searchtype=author&query=Agrawalla%2C+B), [Michal Nauman](https://arxiv.org/search/?searchtype=author&query=Nauman%2C+M), [Khush Agarwal](https://arxiv.org/search/?searchtype=author&query=Agarwal%2C+K), [Aviral Kumar](https://arxiv.org/search/?searchtype=author&query=Kumar%2C+A)

Abstract:  A hallmark of modern large-scale machine learning techniques is the use of training objectives that provide dense supervision to intermediate computations, such as teacher forcing the next token in language models or denoising step-by-step in diffusion models. This enables models to learn complex functions in a generalizable manner. Motivated by this observation, we investigate the benefits of ite… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) A hallmark of modern large-scale machine learning techniques is the use of training objectives that provide dense supervision to intermediate computations, such as teacher forcing the next token in language models or denoising step-by-step in diffusion models. This enables models to learn complex functions in a generalizable manner. Motivated by this observation, we investigate the benefits of iterative computation for temporal difference (TD) methods in reinforcement learning (RL). Typically they represent value functions in a monolithic fashion, without iterative compute. We introduce floq (flow-matching Q-functions), an approach that parameterizes the Q-function using a velocity field and trains it using techniques from flow-matching, typically used in generative modeling. This velocity field underneath the flow is trained using a TD-learning objective, which bootstraps from values produced by a target velocity field, computed by running multiple steps of numerical integration. Crucially, floq allows for more fine-grained control and scaling of the Q-function capacity than monolithic architectures, by appropriately setting the number of integration steps. Across a suite of challenging offline RL benchmarks and online fine-tuning tasks, floq improves performance by nearly 1.8x. floq scales capacity far better than standard TD-learning architectures, highlighting the potential of iterative computation for value learning. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

20.   [arXiv:2509.06861](https://arxiv.org/abs/2509.06861)[[pdf](https://arxiv.org/pdf/2509.06861), [ps](https://arxiv.org/ps/2509.06861), [other](https://arxiv.org/format/2509.06861)]

cs.AI cs.CL cs.LG  
Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet

Authors:[James Xu Zhao](https://arxiv.org/search/?searchtype=author&query=Zhao%2C+J+X), [Bryan Hooi](https://arxiv.org/search/?searchtype=author&query=Hooi%2C+B), [See-Kiong Ng](https://arxiv.org/search/?searchtype=author&query=Ng%2C+S)

Abstract:  Test-time scaling increases inference-time computation by allowing models to generate long reasoning chains, and has shown strong performance across many domains. However, in this work, we show that this approach is not yet effective for knowledge-intensive tasks, where high factual accuracy and low hallucination rates are essential. We conduct a comprehensive evaluation of test-time scaling using… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Test-time scaling increases inference-time computation by allowing models to generate long reasoning chains, and has shown strong performance across many domains. However, in this work, we show that this approach is not yet effective for knowledge-intensive tasks, where high factual accuracy and low hallucination rates are essential. We conduct a comprehensive evaluation of test-time scaling using 12 reasoning models on two knowledge-intensive benchmarks. Our results reveal that increasing test-time computation does not consistently improve accuracy and, in many cases, it even leads to more hallucinations. We then analyze how extended reasoning affects hallucination behavior. We find that reduced hallucinations often result from the model choosing to abstain after thinking more, rather than from improved factual recall. Conversely, for some models, longer reasoning encourages attempts on previously unanswered questions, many of which result in hallucinations. Case studies show that extended reasoning can induce confirmation bias, leading to overconfident hallucinations. Despite these limitations, we observe that compared to non-thinking, enabling thinking remains beneficial. Code and data are available at https://github.com/XuZhao0/tts-knowledge [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

Comments:20 pages, 4 figures, 6 tables

21.   [arXiv:2509.04650](https://arxiv.org/abs/2509.04650)[[pdf](https://arxiv.org/pdf/2509.04650), [ps](https://arxiv.org/ps/2509.04650), [other](https://arxiv.org/format/2509.04650)]

cs.CL cs.AI  
Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety

Authors:[Sharif Noor Zisad](https://arxiv.org/search/?searchtype=author&query=Zisad%2C+S+N), [N. M. Istiak Chowdhury](https://arxiv.org/search/?searchtype=author&query=Chowdhury%2C+N+M+I), [Ragib Hasan](https://arxiv.org/search/?searchtype=author&query=Hasan%2C+R)

Abstract:  Twitter and other social media platforms have become vital sources of real time information during disasters and public safety emergencies. Automatically classifying disaster related tweets can help emergency services respond faster and more effectively. Traditional Machine Learning (ML) models such as Logistic Regression, Naive Bayes, and Support Vector Machines have been widely used for this tas… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Twitter and other social media platforms have become vital sources of real time information during disasters and public safety emergencies. Automatically classifying disaster related tweets can help emergency services respond faster and more effectively. Traditional Machine Learning (ML) models such as Logistic Regression, Naive Bayes, and Support Vector Machines have been widely used for this task, but they often fail to understand the context or deeper meaning of words, especially when the language is informal, metaphorical, or ambiguous. We posit that, in this context, transformer based models can perform better than traditional ML models. In this paper, we evaluate the effectiveness of transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for classifying disaster related tweets. These models are compared with traditional ML approaches to highlight the performance gap. Experimental results show that BERT achieved the highest accuracy (91%), significantly outperforming traditional models like Logistic Regression and Naive Bayes (both at 82%). The use of contextual embeddings and attention mechanisms allows transformer models to better understand subtle language in tweets, where traditional ML models fall short. This research demonstrates that transformer architectures are far more suitable for public safety applications, offering improved accuracy, deeper language understanding, and better generalization across real world social media text. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; v1 submitted 4 September, 2025; originally announced September 2025.

22.   [arXiv:2509.06858](https://arxiv.org/abs/2509.06858)[[pdf](https://arxiv.org/pdf/2509.06858), [ps](https://arxiv.org/ps/2509.06858), [other](https://arxiv.org/format/2509.06858)]

physics.soc-ph cs.AI nlin.AO  
Disentangling Interaction and Bias Effects in Opinion Dynamics of Large Language Models

Authors:[Vincent C. Brockers](https://arxiv.org/search/?searchtype=author&query=Brockers%2C+V+C), [David A. Ehrlich](https://arxiv.org/search/?searchtype=author&query=Ehrlich%2C+D+A), [Viola Priesemann](https://arxiv.org/search/?searchtype=author&query=Priesemann%2C+V)

Abstract:  Large Language Models are increasingly used to simulate human opinion dynamics, yet the effect of genuine interaction is often obscured by systematic biases. We present a Bayesian framework to disentangle and quantify three such biases: (i) a topic bias toward prior opinions in the training data; (ii) an agreement bias favoring agreement irrespective of the question; and (iii) an anchoring bias to… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Large Language Models are increasingly used to simulate human opinion dynamics, yet the effect of genuine interaction is often obscured by systematic biases. We present a Bayesian framework to disentangle and quantify three such biases: (i) a topic bias toward prior opinions in the training data; (ii) an agreement bias favoring agreement irrespective of the question; and (iii) an anchoring bias toward the initiating agent's stance. Applying this framework to multi-step dialogues reveals that opinion trajectories tend to quickly converge to a shared attractor, with the influence of the interaction fading over time, and the impact of biases differing between LLMs. In addition, we fine-tune an LLM on different sets of strongly opinionated statements (incl. misinformation) and demonstrate that the opinion attractor shifts correspondingly. Exposing stark differences between LLMs and providing quantitative tools to compare them to human subjects in the future, our approach highlights both chances and pitfalls in using LLMs as proxies for human behavior. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

23.   [arXiv:2509.06854](https://arxiv.org/abs/2509.06854)[[pdf](https://arxiv.org/pdf/2509.06854)]

cs.CV cs.AI  
Automated Radiographic Total Sharp Score (ARTSS) in Rheumatoid Arthritis: A Solution to Reduce Inter-Intra Reader Variation and Enhancing Clinical Practice

Authors:[Hajar Moradmand](https://arxiv.org/search/?searchtype=author&query=Moradmand%2C+H), [Lei Ren](https://arxiv.org/search/?searchtype=author&query=Ren%2C+L)

Abstract:  Assessing the severity of rheumatoid arthritis (RA) using the Total Sharp/Van Der Heijde Score (TSS) is crucial, but manual scoring is often time-consuming and subjective. This study introduces an Automated Radiographic Sharp Scoring (ARTSS) framework that leverages deep learning to analyze full-hand X-ray images, aiming to reduce inter- and intra-observer variability. The research uniquely accomm… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Assessing the severity of rheumatoid arthritis (RA) using the Total Sharp/Van Der Heijde Score (TSS) is crucial, but manual scoring is often time-consuming and subjective. This study introduces an Automated Radiographic Sharp Scoring (ARTSS) framework that leverages deep learning to analyze full-hand X-ray images, aiming to reduce inter- and intra-observer variability. The research uniquely accommodates patients with joint disappearance and variable-length image sequences. We developed ARTSS using data from 970 patients, structured into four stages: I) Image pre-processing and re-orientation using ResNet50, II) Hand segmentation using UNet.3, III) Joint identification using YOLOv7, and IV) TSS prediction using models such as VGG16, VGG19, ResNet50, DenseNet201, EfficientNetB0, and Vision Transformer (ViT). We evaluated model performance with Intersection over Union (IoU), Mean Average Precision (MAP), mean absolute error (MAE), Root Mean Squared Error (RMSE), and Huber loss. The average TSS from two radiologists was used as the ground truth. Model training employed 3-fold cross-validation, with each fold consisting of 452 training and 227 validation samples, and external testing included 291 unseen subjects. Our joint identification model achieved 99% accuracy. The best-performing model, ViT, achieved a notably low Huber loss of 0.87 for TSS prediction. Our results demonstrate the potential of deep learning to automate RA scoring, which can significantly enhance clinical practice. Our approach addresses the challenge of joint disappearance and variable joint numbers, offers timesaving benefits, reduces inter- and intra-reader variability, improves radiologist accuracy, and aids rheumatologists in making more informed decisions. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

24.   [arXiv:2509.06853](https://arxiv.org/abs/2509.06853)[[pdf](https://arxiv.org/pdf/2509.06853), [ps](https://arxiv.org/ps/2509.06853), [other](https://arxiv.org/format/2509.06853)]

eess.SY cs.AI cs.LG  
Reinforcement learning meets bioprocess control through behaviour cloning: Real-world deployment in an industrial photobioreactor

Authors:[Juan D. Gil](https://arxiv.org/search/?searchtype=author&query=Gil%2C+J+D), [Ehecatl Antonio Del Rio Chanona](https://arxiv.org/search/?searchtype=author&query=Chanona%2C+E+A+D+R), [José L. Guzmán](https://arxiv.org/search/?searchtype=author&query=Guzm%C3%A1n%2C+J+L), [Manuel Berenguel](https://arxiv.org/search/?searchtype=author&query=Berenguel%2C+M)

Abstract:  The inherent complexity of living cells as production units creates major challenges for maintaining stable and optimal bioprocess conditions, especially in open Photobioreactors (PBRs) exposed to fluctuating environments. To address this, we propose a Reinforcement Learning (RL) control approach, combined with Behavior Cloning (BC), for pH regulation in open PBR systems. This represents, to the b… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) The inherent complexity of living cells as production units creates major challenges for maintaining stable and optimal bioprocess conditions, especially in open Photobioreactors (PBRs) exposed to fluctuating environments. To address this, we propose a Reinforcement Learning (RL) control approach, combined with Behavior Cloning (BC), for pH regulation in open PBR systems. This represents, to the best of our knowledge, the first application of an RL-based control strategy to such a nonlinear and disturbance-prone bioprocess. Our method begins with an offline training stage in which the RL agent learns from trajectories generated by a nominal Proportional-Integral-Derivative (PID) controller, without direct interaction with the real system. This is followed by a daily online fine-tuning phase, enabling adaptation to evolving process dynamics and stronger rejection of fast, transient disturbances. This hybrid offline-online strategy allows deployment of an adaptive control policy capable of handling the inherent nonlinearities and external perturbations in open PBRs. Simulation studies highlight the advantages of our method: the Integral of Absolute Error (IAE) was reduced by 8% compared to PID control and by 5% relative to standard off-policy RL. Moreover, control effort decreased substantially-by 54% compared to PID and 7% compared to standard RL-an important factor for minimizing operational costs. Finally, an 8-day experimental validation under varying environmental conditions confirmed the robustness and reliability of the proposed approach. Overall, this work demonstrates the potential of RL-based methods for bioprocess control and paves the way for their broader application to other nonlinear, disturbance-prone systems. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

25.   [arXiv:2509.06836](https://arxiv.org/abs/2509.06836)[[pdf](https://arxiv.org/pdf/2509.06836), [ps](https://arxiv.org/ps/2509.06836), [other](https://arxiv.org/format/2509.06836)]

cs.CL cs.AI cs.LG  
COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens

Authors:[Eugene Kwek](https://arxiv.org/search/?searchtype=author&query=Kwek%2C+E), [Wenpeng Yin](https://arxiv.org/search/?searchtype=author&query=Yin%2C+W)

Abstract:  Making LLMs more efficient in memory, latency, and serving cost is crucial for edge deployment, interactive applications, and sustainable inference at scale. Pruning is a key technique toward this goal. However, prior pruning methods are limited: width pruning often breaks the standard transformer layout or requires custom inference code, while depth pruning removes entire layers and can cause abr… [▽ More](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25) Making LLMs more efficient in memory, latency, and serving cost is crucial for edge deployment, interactive applications, and sustainable inference at scale. Pruning is a key technique toward this goal. However, prior pruning methods are limited: width pruning often breaks the standard transformer layout or requires custom inference code, while depth pruning removes entire layers and can cause abrupt accuracy drops. In this work, we propose COMPACT, which jointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii) prunes FFN intermediate channels using common-token-weighted activations, aligning importance with the post-pruning token distribution. COMPACT enjoys merits of both depth and width pruning, such as: deployment-friendliness (keeps a standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN pruning), training-free operation with competitive pruning time, and strong memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and Gemma families (0.5B-70B) show state-of-the-art downstream task performance at similar or higher pruning ratios, with substantial reductions in parameters, GPU memory, and end-to-end latency. [△ Less](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)

Submitted 8 September, 2025; originally announced September 2025.

[Previous](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25)[Next](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=25)
*   [1](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=0)
*   [2](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=25)
*   [3](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=50)
*   [4](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=75)
*   [5](https://arxiv.org/search/?query=cs.AI&searchtype=all&abstracts=show&order=-submitted_date&size=25&start=100)
*   …

[Search v0.5.6 released 2020-02-24](https://github.com/arXiv/arxiv-search/releases)

*   [About](https://info.arxiv.org/about)
*   [Help](https://info.arxiv.org/help)

*   [Contact](https://info.arxiv.org/help/contact.html)
*   [Subscribe](https://info.arxiv.org/help/subscribe)

*   [Copyright](https://info.arxiv.org/help/license/index.html)
*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)

*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)
*   [arXiv Operational Status](https://status.arxiv.org/)

 Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)

